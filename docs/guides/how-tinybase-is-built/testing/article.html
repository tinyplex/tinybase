<nav><ul><li><a href="/">TinyBase</a></li><li><a href="/guides/">Guides</a></li><li><a href="/guides/how-tinybase-is-built/">How TinyBase Is Built</a></li><li><a href="/guides/how-tinybase-is-built/testing/">Testing</a></li></ul></nav><section class="s1" id="/guides/how-tinybase-is-built/testing/" data-id="T2"><h1>Testing</h1><p>Testing is a first-class citizen in <a href="/">TinyBase</a>, as you may see from the high coverage it enjoys.</p><p>All testing is coordinated by Jest, and test are all found in the <code>test</code> directory within the project.</p><p>The unit tests (in the <code>unit</code> subdirectory), given their names and test titles, should be self-explanatory - there&#x27;s typically one or two per main module. Note that the tests are run against the debug build of the modules, so they require the <code>compileForTest</code> task to have been run, as described in the <a href="/guides/how-tinybase-is-built/developing-tinybase/">Developing TinyBase</a> guide.</p><p>Interestingly, the unit tests also include testing all the code snippets in the API documentation and the guides. This means that it&#x27;s guaranteed that all example code will run correctly, and also (given the number of docs) provides a little bit of extra coverage. The magic to do this (which is alarmingly dependent on regular expressions) is in the <code>documentation.test.ts</code> file.</p><p>There are a few helper functions for the tests. These do things like track listener calls and enumerate complex object structures so they can be easily asserted with.</p><p>The <code>perf</code> subdirectory contains the performance tests. These benchmark large numbers of operations to check for time-complexity. Note that <a href="/">TinyBase</a> performance tests do not have particularly aggressive pass or fail thresholds per se, since the absolute numbers will depend on underlying hardware. However, every test will render an ASCII chart which should be relatively flat. The idea here is that you can check visually that you haven&#x27;t introduced a high time-complexity algorithm bug. For example:</p><pre><code>Grow store, different table to index with multiple row count, µs per row
First: 16.3 µs per row
 Last: 3.61 µs per row
  Min: 2.76 µs per row
  Max: 29.89 µs per row
  Avg: 7.33 µs per row

      90.00 ┼───────────────────────────────────────
      84.00 ┤
      78.00 ┤
      72.00 ┤
      66.00 ┤
      60.00 ┤
      54.00 ┤
      48.00 ┤
      42.00 ┤
      36.00 ┤
      30.00 ┤╭╮
      24.00 ┤││     ╭╮
      18.00 ┼╯│     ││         ╭╮
      12.00 ┤ ╰╮   ╭╯│    ╭╮   ││          ╭╮
       6.00 ┼──╰───╯─╰────╯╰───╯╰──────────╯╰╮──╭───
       0.00 ┤                                ╰──╯
</code></pre><p>Finally, the end-to-end tests in the <code>e2e</code> subdirectory run Puppeteer scripts to drive simple transactions through the demos on the <a href="/">TinyBase</a> website. These are good ways of catching major regressions when more complex apps are put together.</p></section>